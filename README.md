# TFS19s-NLP-Jokes
По мотивам <a href="https://amoudgl.github.io/blog/funnybot/">поста</a> запилить бота, который шутит шутейки.

## План проекта
### 1. Сбор данных (Alexandr Yu., Vasily Karmazin) 
##### дедлайн до 8 апреля
Сбор шутейк из <a href="https://vk.com">vk.com</a>, <a href="https://bash.im">bash.im</a>, <a href="https://2ch.hk">2ch.hk</a> и других подобных ресурсах

### 2. Препроцессинг данных (Alexandr Yu.) 
##### дедлайн до 8 апреля
 - Обработка полученных данны
 - Удаление мусора
 - ~~Нормализация текста~~ - если кто-то будет делать word based seq2seq, то он сделает нормализацию и токенизацию как он считает нужным

### 3. Создание архитектуры проекта (Alexandr Yu., Vasily Karmazin, Vlad Semak) 
##### дедлайн до 21 апреля
Изучение дополнительного материала
 - Статьи (<a href="https://guillaumegenthial.github.io/sequence-to-sequence.html">Seq2Seq with Attention and Beam Search</a>)
 - Похожие проекты 
 - Научные работы
 
### 4. Эксперимент 1. LSTM/RNN, Seq2Seq (Alexandr Yu., Vlad Semak) 
##### дедлайн до 15 апреля
Построение простой модели и оценка её качества

### 5. Эксперимент 2. Attention (Aexandr Yu., Vasily Karmazin) 
##### дедлайн до 19 апреля
Добавление attention-а к модели 

### 6. Эксперимент 3. Language Model, ULMFiT (Alexandr Yu., Vasily Karmazin, Vlad Semak) 
##### дедлайн до 21 апреля
Изучение сложных архитектурных моделей, попытки использовать transfer learning в проекте 

### -1. (опционально) Телеграмм бот (Vasily Karmazin)
Создание телеграмм бота для удобства демонстрации проекта



## Результаты 
### Эксперимент 1. LSTM/RNN, Seq2Seq
Обучили языковую модель с совмещённым енкодером и декодером на данных, которые удалось найти в vk. В датасете примерно 7к коротких шуток

Использовали двухслойную LSTM со скрытым слоем в 256. Для букв используются эмбединги размерности 128. Предсказания делаются на основе Beam Search с шириной поиска в 5

Обученную модель можно скачать [тут](https://yadi.sk/d/nnW4KkXJasQ7kA)

Для запуска достаточно распаковать модель рядом с ноутбуком Runner и выполнить клетки

Примеры работы модели. В данном варианте, для генерации шуток подаём модели рандомную строку

```
весилый знакомств.
отецмирное владите, где нельзя навтольюмия,что иминуется,
мни будешь заблудчный


сейческин студентов.ребральных футболщины!
препысняли, изолиланы, приобрести противолноршкий балы...


из лондской фоткальными....свелочные музаков
пожалуйте навалилизировать, чтобы японцевые...


кто наливших фильмо" отлиодов...диблядов. похиратильные писсывает:
"черудический пукаживия...
заяц....


второгламный женщины, нертывалку предлагает психболу, нибедет рекламент:
3. бум"греточным, населенное зронят
залагивались...
```

### Эксперимент 2. Attention
Спарсили <a href="https://anekdot.ru">anekdot.ru</a> и наш датасет увеличился до примерно 55к шуток

Использовали [textgenrnn](https://github.com/minimaxir/textgenrnn), где реализован механизм attention-а

Модель с rnn_layers=4, layer_size=128, dim_embeddings=100

Длительность обучения - 15 эпох, ~ 3 часов в colab’е


```
шутки
```


### Эксперимент 3. Language Model, ULMFiT
Попробовали использовать уже обученную на русских текстах языковую модель и затрансферить её на наш датасет

Использовали библиотеку [fastai](https://docs.fast.ai/) и [обученную AWD-LSTM](https://github.com/mamamot/Russian-ULMFit) модель как базовую 

Получили word based модель

Длительность обучения - ХХХ эпох, ~ ХХХ часов в colab’е

```
шутки
```


### Телеграмм бот
Команды бота 
```
/joke (/j) - генерация шуток (ULMFiT AWD-LSTM)
/joke_t (/jt) {temperature} - генерация шуток с температурой [0.1, 1.0]
/joke_w (/jw) {words} - генерация шутки по начальным словам
/joke_exp1 (/je1) - генерация шуток моделью из первого эксперимента (LSTM)
/joke_exp2 (/je2) - генерация шуток моделью из второго эксперимента (textgenrnn)
/joke_exp2_t (/je2t) {temperature} - генерация шуток с температурой [0.1, 1.0] (textgenrnn)
/help (/h) - помощь
/about (/a) - об авторах
Примеры:
/joke_t 0.8
/joke_w Решил я сделать бота шутника, а он
/je2t 0.4
```
Для запуска бота нужно предварительно скачать модели в папку data. Скачать наши модели можно [тут](https:) 

Мы запускаем бота через colab, инструкции есть в colab_runner.ipynb. Можно запустить бота на локальной машине командой:

```
!python3 shutki_bot.py -t {TOKEN} [-p {path_to_data}]
```

Где TOKEN - это токен для доступа к HTTP API бота
